Parameters of each component:
-------------------------------------------------------------------------------------------------
Component                                               Parameters                    Matrix Size
-------------------------------------------------------------------------------------------------
embedding                                               32,164,480       torch.Size([50257, 640])
-------------------------------------------------------------------------------------------------
transformer_block_0                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_0                                       655,360        torch.Size([1024, 640])
  attention_k_proj_0                                       163,840         torch.Size([256, 640])
  attention_v_proj_0                                       163,840         torch.Size([256, 640])
  attention_out_proj_0                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_0                                            640              torch.Size([640])
  post_attention_layernorm_0                                   640              torch.Size([640])
  q_norm_0                                                     256              torch.Size([256])
  k_norm_0                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_0                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_0                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_0                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_0                                  640              torch.Size([640])
  post_feedforward_layernorm_0                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_1                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_1                                       655,360        torch.Size([1024, 640])
  attention_k_proj_1                                       163,840         torch.Size([256, 640])
  attention_v_proj_1                                       163,840         torch.Size([256, 640])
  attention_out_proj_1                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_1                                            640              torch.Size([640])
  post_attention_layernorm_1                                   640              torch.Size([640])
  q_norm_1                                                     256              torch.Size([256])
  k_norm_1                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_1                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_1                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_1                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_1                                  640              torch.Size([640])
  post_feedforward_layernorm_1                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_2                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_2                                       655,360        torch.Size([1024, 640])
  attention_k_proj_2                                       163,840         torch.Size([256, 640])
  attention_v_proj_2                                       163,840         torch.Size([256, 640])
  attention_out_proj_2                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_2                                            640              torch.Size([640])
  post_attention_layernorm_2                                   640              torch.Size([640])
  q_norm_2                                                     256              torch.Size([256])
  k_norm_2                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_2                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_2                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_2                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_2                                  640              torch.Size([640])
  post_feedforward_layernorm_2                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_3                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_3                                       655,360        torch.Size([1024, 640])
  attention_k_proj_3                                       163,840         torch.Size([256, 640])
  attention_v_proj_3                                       163,840         torch.Size([256, 640])
  attention_out_proj_3                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_3                                            640              torch.Size([640])
  post_attention_layernorm_3                                   640              torch.Size([640])
  q_norm_3                                                     256              torch.Size([256])
  k_norm_3                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_3                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_3                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_3                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_3                                  640              torch.Size([640])
  post_feedforward_layernorm_3                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_4                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_4                                       655,360        torch.Size([1024, 640])
  attention_k_proj_4                                       163,840         torch.Size([256, 640])
  attention_v_proj_4                                       163,840         torch.Size([256, 640])
  attention_out_proj_4                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_4                                            640              torch.Size([640])
  post_attention_layernorm_4                                   640              torch.Size([640])
  q_norm_4                                                     256              torch.Size([256])
  k_norm_4                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_4                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_4                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_4                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_4                                  640              torch.Size([640])
  post_feedforward_layernorm_4                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_5                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_5                                       655,360        torch.Size([1024, 640])
  attention_k_proj_5                                       163,840         torch.Size([256, 640])
  attention_v_proj_5                                       163,840         torch.Size([256, 640])
  attention_out_proj_5                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_5                                            640              torch.Size([640])
  post_attention_layernorm_5                                   640              torch.Size([640])
  q_norm_5                                                     256              torch.Size([256])
  k_norm_5                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_5                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_5                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_5                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_5                                  640              torch.Size([640])
  post_feedforward_layernorm_5                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_6                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_6                                       655,360        torch.Size([1024, 640])
  attention_k_proj_6                                       163,840         torch.Size([256, 640])
  attention_v_proj_6                                       163,840         torch.Size([256, 640])
  attention_out_proj_6                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_6                                            640              torch.Size([640])
  post_attention_layernorm_6                                   640              torch.Size([640])
  q_norm_6                                                     256              torch.Size([256])
  k_norm_6                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_6                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_6                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_6                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_6                                  640              torch.Size([640])
  post_feedforward_layernorm_6                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_7                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_7                                       655,360        torch.Size([1024, 640])
  attention_k_proj_7                                       163,840         torch.Size([256, 640])
  attention_v_proj_7                                       163,840         torch.Size([256, 640])
  attention_out_proj_7                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_7                                            640              torch.Size([640])
  post_attention_layernorm_7                                   640              torch.Size([640])
  q_norm_7                                                     256              torch.Size([256])
  k_norm_7                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_7                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_7                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_7                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_7                                  640              torch.Size([640])
  post_feedforward_layernorm_7                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_8                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_8                                       655,360        torch.Size([1024, 640])
  attention_k_proj_8                                       163,840         torch.Size([256, 640])
  attention_v_proj_8                                       163,840         torch.Size([256, 640])
  attention_out_proj_8                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_8                                            640              torch.Size([640])
  post_attention_layernorm_8                                   640              torch.Size([640])
  q_norm_8                                                     256              torch.Size([256])
  k_norm_8                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_8                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_8                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_8                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_8                                  640              torch.Size([640])
  post_feedforward_layernorm_8                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_9                                      5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_9                                       655,360        torch.Size([1024, 640])
  attention_k_proj_9                                       163,840         torch.Size([256, 640])
  attention_v_proj_9                                       163,840         torch.Size([256, 640])
  attention_out_proj_9                                     655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_9                                            640              torch.Size([640])
  post_attention_layernorm_9                                   640              torch.Size([640])
  q_norm_9                                                     256              torch.Size([256])
  k_norm_9                                                     256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_9                                              1,310,720        torch.Size([2048, 640])
  mlp_fc2_9                                              1,310,720        torch.Size([2048, 640])
  mlp_fc3_9                                              1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_9                                  640              torch.Size([640])
  post_feedforward_layernorm_9                                 640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_10                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_10                                      655,360        torch.Size([1024, 640])
  attention_k_proj_10                                      163,840         torch.Size([256, 640])
  attention_v_proj_10                                      163,840         torch.Size([256, 640])
  attention_out_proj_10                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_10                                           640              torch.Size([640])
  post_attention_layernorm_10                                  640              torch.Size([640])
  q_norm_10                                                    256              torch.Size([256])
  k_norm_10                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_10                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_10                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_10                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_10                                 640              torch.Size([640])
  post_feedforward_layernorm_10                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_11                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_11                                      655,360        torch.Size([1024, 640])
  attention_k_proj_11                                      163,840         torch.Size([256, 640])
  attention_v_proj_11                                      163,840         torch.Size([256, 640])
  attention_out_proj_11                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_11                                           640              torch.Size([640])
  post_attention_layernorm_11                                  640              torch.Size([640])
  q_norm_11                                                    256              torch.Size([256])
  k_norm_11                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_11                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_11                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_11                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_11                                 640              torch.Size([640])
  post_feedforward_layernorm_11                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_12                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_12                                      655,360        torch.Size([1024, 640])
  attention_k_proj_12                                      163,840         torch.Size([256, 640])
  attention_v_proj_12                                      163,840         torch.Size([256, 640])
  attention_out_proj_12                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_12                                           640              torch.Size([640])
  post_attention_layernorm_12                                  640              torch.Size([640])
  q_norm_12                                                    256              torch.Size([256])
  k_norm_12                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_12                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_12                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_12                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_12                                 640              torch.Size([640])
  post_feedforward_layernorm_12                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_13                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_13                                      655,360        torch.Size([1024, 640])
  attention_k_proj_13                                      163,840         torch.Size([256, 640])
  attention_v_proj_13                                      163,840         torch.Size([256, 640])
  attention_out_proj_13                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_13                                           640              torch.Size([640])
  post_attention_layernorm_13                                  640              torch.Size([640])
  q_norm_13                                                    256              torch.Size([256])
  k_norm_13                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_13                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_13                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_13                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_13                                 640              torch.Size([640])
  post_feedforward_layernorm_13                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_14                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_14                                      655,360        torch.Size([1024, 640])
  attention_k_proj_14                                      163,840         torch.Size([256, 640])
  attention_v_proj_14                                      163,840         torch.Size([256, 640])
  attention_out_proj_14                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_14                                           640              torch.Size([640])
  post_attention_layernorm_14                                  640              torch.Size([640])
  q_norm_14                                                    256              torch.Size([256])
  k_norm_14                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_14                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_14                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_14                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_14                                 640              torch.Size([640])
  post_feedforward_layernorm_14                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_15                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_15                                      655,360        torch.Size([1024, 640])
  attention_k_proj_15                                      163,840         torch.Size([256, 640])
  attention_v_proj_15                                      163,840         torch.Size([256, 640])
  attention_out_proj_15                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_15                                           640              torch.Size([640])
  post_attention_layernorm_15                                  640              torch.Size([640])
  q_norm_15                                                    256              torch.Size([256])
  k_norm_15                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_15                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_15                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_15                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_15                                 640              torch.Size([640])
  post_feedforward_layernorm_15                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_16                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_16                                      655,360        torch.Size([1024, 640])
  attention_k_proj_16                                      163,840         torch.Size([256, 640])
  attention_v_proj_16                                      163,840         torch.Size([256, 640])
  attention_out_proj_16                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_16                                           640              torch.Size([640])
  post_attention_layernorm_16                                  640              torch.Size([640])
  q_norm_16                                                    256              torch.Size([256])
  k_norm_16                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_16                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_16                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_16                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_16                                 640              torch.Size([640])
  post_feedforward_layernorm_16                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
transformer_block_17                                     5,573,632                               
-------------------------------------------------------------------------------------------------
  attention_q_proj_17                                      655,360        torch.Size([1024, 640])
  attention_k_proj_17                                      163,840         torch.Size([256, 640])
  attention_v_proj_17                                      163,840         torch.Size([256, 640])
  attention_out_proj_17                                    655,360        torch.Size([640, 1024])
-------------------------------------------------------------------------------------------------
  input_layernorm_17                                           640              torch.Size([640])
  post_attention_layernorm_17                                  640              torch.Size([640])
  q_norm_17                                                    256              torch.Size([256])
  k_norm_17                                                    256              torch.Size([256])
-------------------------------------------------------------------------------------------------
  mlp_fc1_17                                             1,310,720        torch.Size([2048, 640])
  mlp_fc2_17                                             1,310,720        torch.Size([2048, 640])
  mlp_fc3_17                                             1,310,720        torch.Size([640, 2048])
-------------------------------------------------------------------------------------------------
  pre_feedforward_layernorm_17                                 640              torch.Size([640])
  post_feedforward_layernorm_17                                640              torch.Size([640])
-------------------------------------------------------------------------------------------------
final_norm                                                     640              torch.Size([640])
-------------------------------------------------------------------------------------------------
output_layer                                       (Tied to embedding)            (Tied to embedding)
-------------------------------------------------------------------------------------------------
Total                                                  132,490,496                               

Verification successful: Calculated total matches trainable model parameters.