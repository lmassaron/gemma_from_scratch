{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lmassaron/gemma_from_scratch/blob/main/Gemma_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pqpPj6rBiV5v"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac7424e9",
    "outputId": "f0496c1b-f5e5-4cc9-f55b-26362d49107f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M99_fRZJRCHX",
    "outputId": "b2e92775-dfd1-46e5-f21d-b8a9a3cdecf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gemma_from_scratch'...\n",
      "remote: Enumerating objects: 110, done.\u001b[K\n",
      "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
      "remote: Total 110 (delta 59), reused 76 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (110/110), 77.70 KiB | 2.99 MiB/s, done.\n",
      "Resolving deltas: 100% (59/59), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lmassaron/gemma_from_scratch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpFR8rSiRD_a",
    "outputId": "73486468-6b17-4b6a-a275-db4fc9b804ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gemma_from_scratch\n"
     ]
    }
   ],
   "source": [
    "cd gemma_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHtgvxQhRNNS",
    "outputId": "ccc3da79-f0e0-4cdb-81ac-76861588937a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISONS.md             LICENSE             README.md\n",
      "\u001b[0m\u001b[01;34mgemma_scratch\u001b[0m/             loss_plot.png       requirements.txt\n",
      "inference_custom.py        NOTICE              train_from_scratch.py\n",
      "inference_google_gemma.py  prepare_dataset.py\n",
      "install.sh                 pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBX1BW-RSCGo",
    "outputId": "d18670a2-8587-4885-bf89-25879acbc0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md: 1.06kB [00:00, 5.89MB/s]\n",
      "data/train-00000-of-00004-2d5a1467fff108(…): 100% 249M/249M [00:01<00:00, 186MB/s]\n",
      "data/train-00001-of-00004-5852b56a2bd28f(…): 100% 248M/248M [00:01<00:00, 205MB/s]\n",
      "data/train-00002-of-00004-a26307300439e9(…): 100% 246M/246M [00:01<00:00, 220MB/s]\n",
      "data/train-00003-of-00004-d243063613e5a0(…): 100% 248M/248M [00:00<00:00, 264MB/s]\n",
      "data/validation-00000-of-00001-869c898b5(…): 100% 9.99M/9.99M [00:00<00:00, 32.4MB/s]\n",
      "Generating train split: 100% 2119719/2119719 [00:06<00:00, 338493.03 examples/s]\n",
      "Generating validation split: 100% 21990/21990 [00:00<00:00, 378765.24 examples/s]\n",
      "Found splits: ['train', 'validation']\n",
      "tokenizing the splits (num_proc=12): 100% 2119719/2119719 [00:58<00:00, 36274.37 examples/s]\n",
      "tokenizing the splits (num_proc=12): 100% 21990/21990 [00:00<00:00, 26151.89 examples/s]\n",
      "writing ./tinystories_data/train.bin: 100% 1024/1024 [14:09<00:00,  1.21it/s]\n",
      "writing ./tinystories_data/val.bin: 100% 1024/1024 [00:10<00:00, 101.53it/s]\n"
     ]
    }
   ],
   "source": [
    "!python prepare_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G30rDOiZAkSi",
    "outputId": "829b7230-9153-48a1-b836-3a04b67af986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-28 07:39:18.986424: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-28 07:39:19.003448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761637159.024531    8023 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761637159.030931    8023 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761637159.046977    8023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761637159.047004    8023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761637159.047009    8023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761637159.047012    8023 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-28 07:39:19.052014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using device: cuda\n",
      "Starting training run 20251028_0739. Saving best model to models/best_model_20251028_0739.pt\n",
      "  0% 500/100000 [00:55<3:02:20,  9.09it/s]\n",
      "Iteration 500: val_loss 10.0791, val_perplexity 23839.8301, val_accuracy 0.0914\n",
      "  1% 1000/100000 [02:05<2:58:23,  9.25it/s]\n",
      "Iteration 1000: val_loss 9.3736, val_perplexity 11773.9736, val_accuracy 0.1382\n",
      "  2% 1500/100000 [03:15<2:54:26,  9.41it/s]\n",
      "Iteration 1500: val_loss 8.8936, val_perplexity 7285.1743, val_accuracy 0.1394\n",
      "  2% 2000/100000 [04:26<2:55:58,  9.28it/s]\n",
      "Iteration 2000: val_loss 8.4800, val_perplexity 4817.5396, val_accuracy 0.1456\n",
      "  2% 2500/100000 [05:36<2:56:16,  9.22it/s]\n",
      "Iteration 2500: val_loss 8.1350, val_perplexity 3411.6509, val_accuracy 0.1562\n",
      "  3% 3000/100000 [06:46<2:55:40,  9.20it/s]\n",
      "Iteration 3000: val_loss 7.8403, val_perplexity 2540.9490, val_accuracy 0.1678\n",
      "  4% 3500/100000 [07:56<2:56:24,  9.12it/s]\n",
      "Iteration 3500: val_loss 7.5356, val_perplexity 1873.5417, val_accuracy 0.1806\n",
      "  4% 4000/100000 [09:06<3:01:03,  8.84it/s]\n",
      "Iteration 4000: val_loss 7.2613, val_perplexity 1424.0919, val_accuracy 0.1930\n",
      "  4% 4500/100000 [10:17<2:53:09,  9.19it/s]\n",
      "Iteration 4500: val_loss 7.0138, val_perplexity 1111.8914, val_accuracy 0.2082\n",
      "  5% 5000/100000 [11:27<2:52:22,  9.19it/s]\n",
      "Iteration 5000: val_loss 6.7801, val_perplexity 880.1172, val_accuracy 0.2193\n",
      "  6% 5500/100000 [12:37<2:50:41,  9.23it/s]\n",
      "Iteration 5500: val_loss 6.5935, val_perplexity 730.3260, val_accuracy 0.2254\n",
      "  6% 6000/100000 [13:47<2:51:33,  9.13it/s]\n",
      "Iteration 6000: val_loss 6.4134, val_perplexity 609.9825, val_accuracy 0.2324\n",
      "  6% 6500/100000 [14:57<2:50:11,  9.16it/s]\n",
      "Iteration 6500: val_loss 6.2456, val_perplexity 515.7289, val_accuracy 0.2366\n",
      "  7% 7000/100000 [16:07<2:46:45,  9.29it/s]\n",
      "Iteration 7000: val_loss 6.0828, val_perplexity 438.2740, val_accuracy 0.2429\n",
      "  8% 7500/100000 [17:18<2:46:06,  9.28it/s]\n",
      "Iteration 7500: val_loss 5.9264, val_perplexity 374.7882, val_accuracy 0.2476\n",
      "  8% 8000/100000 [18:28<2:53:29,  8.84it/s]\n",
      "Iteration 8000: val_loss 5.7883, val_perplexity 326.4481, val_accuracy 0.2508\n",
      "  8% 8500/100000 [19:38<2:45:34,  9.21it/s]\n",
      "Iteration 8500: val_loss 5.6533, val_perplexity 285.2337, val_accuracy 0.2541\n",
      "  9% 9000/100000 [20:48<2:46:44,  9.10it/s]\n",
      "Iteration 9000: val_loss 5.5407, val_perplexity 254.8546, val_accuracy 0.2580\n",
      " 10% 9500/100000 [21:58<2:42:34,  9.28it/s]\n",
      "Iteration 9500: val_loss 5.4319, val_perplexity 228.5810, val_accuracy 0.2614\n",
      " 10% 10000/100000 [23:09<2:40:39,  9.34it/s]\n",
      "Iteration 10000: val_loss 5.3222, val_perplexity 204.8326, val_accuracy 0.2652\n",
      " 10% 10500/100000 [24:19<2:43:33,  9.12it/s]\n",
      "Iteration 10500: val_loss 5.2214, val_perplexity 185.1995, val_accuracy 0.2696\n",
      " 11% 11000/100000 [25:30<2:39:26,  9.30it/s]\n",
      "Iteration 11000: val_loss 5.1461, val_perplexity 171.7608, val_accuracy 0.2724\n",
      " 12% 11500/100000 [26:40<2:39:01,  9.28it/s]\n",
      "Iteration 11500: val_loss 5.0718, val_perplexity 159.4652, val_accuracy 0.2758\n",
      " 12% 12000/100000 [27:50<2:47:53,  8.74it/s]\n",
      "Iteration 12000: val_loss 4.9889, val_perplexity 146.7775, val_accuracy 0.2799\n",
      " 12% 12500/100000 [29:00<2:38:21,  9.21it/s]\n",
      "Iteration 12500: val_loss 4.9326, val_perplexity 138.7430, val_accuracy 0.2815\n",
      " 13% 13000/100000 [30:10<2:36:59,  9.24it/s]\n",
      "Iteration 13000: val_loss 4.8647, val_perplexity 129.6258, val_accuracy 0.2853\n",
      " 14% 13500/100000 [31:20<2:36:15,  9.23it/s]\n",
      "Iteration 13500: val_loss 4.8057, val_perplexity 122.2038, val_accuracy 0.2864\n",
      " 14% 14000/100000 [32:31<2:35:33,  9.21it/s]\n",
      "Iteration 14000: val_loss 4.7342, val_perplexity 113.7760, val_accuracy 0.2901\n",
      " 14% 14500/100000 [33:41<2:36:17,  9.12it/s]\n",
      "Iteration 14500: val_loss 4.6557, val_perplexity 105.1842, val_accuracy 0.2921\n",
      " 15% 15000/100000 [34:51<2:36:36,  9.05it/s]\n",
      "Iteration 15000: val_loss 4.5715, val_perplexity 96.6847, val_accuracy 0.2969\n",
      " 16% 15500/100000 [36:02<2:33:47,  9.16it/s]\n",
      "Iteration 15500: val_loss 4.4842, val_perplexity 88.6044, val_accuracy 0.2994\n",
      " 16% 16000/100000 [37:12<2:37:28,  8.89it/s]\n",
      "Iteration 16000: val_loss 4.4038, val_perplexity 81.7591, val_accuracy 0.3025\n",
      " 16% 16500/100000 [38:22<2:29:33,  9.31it/s]\n",
      "Iteration 16500: val_loss 4.3643, val_perplexity 78.5917, val_accuracy 0.3039\n",
      " 17% 17000/100000 [39:33<2:34:42,  8.94it/s]\n",
      "Iteration 17000: val_loss 4.2802, val_perplexity 72.2518, val_accuracy 0.3086\n",
      " 18% 17500/100000 [40:43<2:30:06,  9.16it/s]\n",
      "Iteration 17500: val_loss 4.2038, val_perplexity 66.9406, val_accuracy 0.3109\n",
      " 18% 18000/100000 [41:54<2:33:16,  8.92it/s]\n",
      "Iteration 18000: val_loss 4.1578, val_perplexity 63.9290, val_accuracy 0.3126\n",
      " 18% 18500/100000 [43:04<2:27:38,  9.20it/s]\n",
      "Iteration 18500: val_loss 4.0980, val_perplexity 60.2194, val_accuracy 0.3148\n",
      " 19% 19000/100000 [44:14<2:26:24,  9.22it/s]\n",
      "Iteration 19000: val_loss 4.0549, val_perplexity 57.6770, val_accuracy 0.3174\n",
      " 20% 19500/100000 [45:25<2:25:33,  9.22it/s]\n",
      "Iteration 19500: val_loss 4.0145, val_perplexity 55.3978, val_accuracy 0.3199\n",
      " 20% 20000/100000 [46:35<2:29:29,  8.92it/s]\n",
      "Iteration 20000: val_loss 3.9570, val_perplexity 52.3003, val_accuracy 0.3224\n",
      " 20% 20500/100000 [47:45<2:24:40,  9.16it/s]\n",
      "Iteration 20500: val_loss 3.9334, val_perplexity 51.0802, val_accuracy 0.3247\n",
      " 21% 21000/100000 [48:56<2:28:37,  8.86it/s]\n",
      "Iteration 21000: val_loss 3.8920, val_perplexity 49.0092, val_accuracy 0.3265\n",
      " 22% 21500/100000 [50:06<2:27:16,  8.88it/s]\n",
      "Iteration 21500: val_loss 3.8621, val_perplexity 47.5642, val_accuracy 0.3283\n",
      " 22% 22000/100000 [51:17<2:22:40,  9.11it/s]\n",
      "Iteration 22000: val_loss 3.8245, val_perplexity 45.8096, val_accuracy 0.3311\n",
      " 22% 22500/100000 [52:27<2:21:45,  9.11it/s]\n",
      "Iteration 22500: val_loss 3.7952, val_perplexity 44.4892, val_accuracy 0.3329\n",
      " 23% 23000/100000 [53:38<2:19:36,  9.19it/s]\n",
      "Iteration 23000: val_loss 3.7651, val_perplexity 43.1679, val_accuracy 0.3362\n",
      " 24% 23500/100000 [54:48<2:17:37,  9.26it/s]\n",
      "Iteration 23500: val_loss 3.7302, val_perplexity 41.6888, val_accuracy 0.3390\n",
      " 24% 24000/100000 [55:59<2:24:12,  8.78it/s]\n",
      "Iteration 24000: val_loss 3.7089, val_perplexity 40.8077, val_accuracy 0.3394\n",
      " 24% 24500/100000 [57:10<2:24:25,  8.71it/s]\n",
      "Iteration 24500: val_loss 3.7050, val_perplexity 40.6500, val_accuracy 0.3399\n",
      " 25% 25000/100000 [58:20<2:17:26,  9.09it/s]\n",
      "Iteration 25000: val_loss 3.6746, val_perplexity 39.4323, val_accuracy 0.3417\n",
      " 26% 25500/100000 [59:31<2:14:26,  9.24it/s]\n",
      "Iteration 25500: val_loss 3.6460, val_perplexity 38.3216, val_accuracy 0.3444\n",
      " 26% 26000/100000 [1:00:41<2:13:52,  9.21it/s]\n",
      "Iteration 26000: val_loss 3.6352, val_perplexity 37.9112, val_accuracy 0.3450\n",
      " 26% 26500/100000 [1:01:51<2:13:02,  9.21it/s]\n",
      "Iteration 26500: val_loss 3.6203, val_perplexity 37.3487, val_accuracy 0.3449\n",
      " 27% 27000/100000 [1:03:02<2:13:39,  9.10it/s]\n",
      "Iteration 27000: val_loss 3.5920, val_perplexity 36.3069, val_accuracy 0.3489\n",
      " 28% 27500/100000 [1:04:13<2:15:43,  8.90it/s]\n",
      "Iteration 27500: val_loss 3.5820, val_perplexity 35.9466, val_accuracy 0.3496\n",
      " 28% 28000/100000 [1:05:23<2:21:05,  8.50it/s]\n",
      "Iteration 28000: val_loss 3.5660, val_perplexity 35.3760, val_accuracy 0.3512\n",
      " 28% 28500/100000 [1:06:34<2:08:52,  9.25it/s]\n",
      "Iteration 28500: val_loss 3.5630, val_perplexity 35.2704, val_accuracy 0.3489\n",
      " 29% 29000/100000 [1:07:45<2:08:27,  9.21it/s]\n",
      "Iteration 29000: val_loss 3.5351, val_perplexity 34.2989, val_accuracy 0.3540\n",
      " 30% 29500/100000 [1:08:55<2:07:27,  9.22it/s]\n",
      "Iteration 29500: val_loss 3.5183, val_perplexity 33.7285, val_accuracy 0.3548\n",
      " 30% 30000/100000 [1:10:06<2:07:27,  9.15it/s]\n",
      "Iteration 30000: val_loss 3.5068, val_perplexity 33.3430, val_accuracy 0.3548\n",
      " 30% 30500/100000 [1:11:17<2:09:25,  8.95it/s]\n",
      "Iteration 30500: val_loss 3.4921, val_perplexity 32.8551, val_accuracy 0.3557\n",
      " 31% 31000/100000 [1:12:27<2:05:51,  9.14it/s]\n",
      "Iteration 31000: val_loss 3.4622, val_perplexity 31.8876, val_accuracy 0.3590\n",
      " 32% 31500/100000 [1:13:38<2:07:21,  8.96it/s]\n",
      "Iteration 31500: val_loss 3.4538, val_perplexity 31.6189, val_accuracy 0.3588\n",
      " 32% 31999/100000 [1:14:48<2:02:40,  9.24it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      " 32% 32000/100000 [1:14:48<2:10:11,  8.70it/s]\n",
      "Iteration 32000: val_loss 3.4319, val_perplexity 30.9356, val_accuracy 0.3635\n",
      " 32% 32500/100000 [1:15:59<2:02:30,  9.18it/s]\n",
      "Iteration 32500: val_loss 3.4136, val_perplexity 30.3733, val_accuracy 0.3644\n",
      " 33% 33000/100000 [1:17:10<2:01:35,  9.18it/s]\n",
      "Iteration 33000: val_loss 3.4120, val_perplexity 30.3244, val_accuracy 0.3650\n",
      " 34% 33500/100000 [1:18:20<1:59:52,  9.25it/s]\n",
      "Iteration 33500: val_loss 3.3929, val_perplexity 29.7510, val_accuracy 0.3662\n",
      " 34% 34000/100000 [1:19:31<1:59:02,  9.24it/s]\n",
      "Iteration 34000: val_loss 3.3731, val_perplexity 29.1695, val_accuracy 0.3676\n",
      " 34% 34500/100000 [1:20:41<1:59:23,  9.14it/s]\n",
      "Iteration 34500: val_loss 3.3721, val_perplexity 29.1405, val_accuracy 0.3673\n",
      " 35% 35000/100000 [1:21:51<2:01:46,  8.90it/s]\n",
      "Iteration 35000: val_loss 3.3538, val_perplexity 28.6115, val_accuracy 0.3691\n",
      " 36% 35500/100000 [1:23:02<1:57:33,  9.14it/s]\n",
      "Iteration 35500: val_loss 3.3357, val_perplexity 28.0979, val_accuracy 0.3708\n",
      " 36% 36000/100000 [1:24:13<2:01:02,  8.81it/s]\n",
      "Iteration 36000: val_loss 3.3351, val_perplexity 28.0817, val_accuracy 0.3712\n",
      " 36% 36500/100000 [1:25:24<1:55:08,  9.19it/s]\n",
      "Iteration 36500: val_loss 3.3223, val_perplexity 27.7246, val_accuracy 0.3711\n",
      " 37% 37000/100000 [1:26:34<1:53:28,  9.25it/s]\n",
      "Iteration 37000: val_loss 3.3221, val_perplexity 27.7185, val_accuracy 0.3716\n",
      " 38% 37500/100000 [1:27:45<1:52:40,  9.24it/s]\n",
      "Iteration 37500: val_loss 3.3030, val_perplexity 27.1937, val_accuracy 0.3742\n",
      " 38% 38000/100000 [1:28:55<1:51:31,  9.27it/s]\n",
      "Iteration 38000: val_loss 3.2914, val_perplexity 26.8809, val_accuracy 0.3738\n",
      " 38% 38500/100000 [1:30:06<1:55:38,  8.86it/s]\n",
      "Iteration 38500: val_loss 3.2805, val_perplexity 26.5897, val_accuracy 0.3763\n",
      " 39% 39000/100000 [1:31:17<1:51:32,  9.11it/s]\n",
      "Iteration 39000: val_loss 3.2724, val_perplexity 26.3757, val_accuracy 0.3779\n",
      " 40% 39500/100000 [1:32:27<1:50:17,  9.14it/s]\n",
      "Iteration 39500: val_loss 3.2640, val_perplexity 26.1530, val_accuracy 0.3783\n",
      " 40% 40000/100000 [1:33:37<1:53:14,  8.83it/s]\n",
      "Iteration 40000: val_loss 3.2488, val_perplexity 25.7605, val_accuracy 0.3800\n",
      " 40% 40500/100000 [1:34:48<1:47:52,  9.19it/s]\n",
      "Iteration 40500: val_loss 3.2432, val_perplexity 25.6159, val_accuracy 0.3805\n",
      " 41% 41000/100000 [1:35:58<1:46:58,  9.19it/s]\n",
      "Iteration 41000: val_loss 3.2367, val_perplexity 25.4504, val_accuracy 0.3810\n",
      " 42% 41500/100000 [1:37:09<1:44:49,  9.30it/s]\n",
      "Iteration 41500: val_loss 3.2362, val_perplexity 25.4373, val_accuracy 0.3813\n",
      " 42% 42000/100000 [1:38:19<1:48:23,  8.92it/s]\n",
      "Iteration 42000: val_loss 3.2215, val_perplexity 25.0655, val_accuracy 0.3822\n",
      " 42% 42500/100000 [1:39:29<1:45:08,  9.12it/s]\n",
      "Iteration 42500: val_loss 3.2181, val_perplexity 24.9815, val_accuracy 0.3830\n",
      " 43% 43000/100000 [1:40:40<1:43:09,  9.21it/s]\n",
      "Iteration 43000: val_loss 3.1992, val_perplexity 24.5125, val_accuracy 0.3850\n",
      " 44% 43500/100000 [1:41:51<1:43:43,  9.08it/s]\n",
      "Iteration 43500: val_loss 3.1979, val_perplexity 24.4823, val_accuracy 0.3859\n",
      " 44% 44000/100000 [1:43:01<1:44:38,  8.92it/s]\n",
      "Iteration 44000: val_loss 3.1889, val_perplexity 24.2617, val_accuracy 0.3859\n",
      " 44% 44500/100000 [1:44:12<1:41:31,  9.11it/s]\n",
      "Iteration 44500: val_loss 3.1840, val_perplexity 24.1436, val_accuracy 0.3865\n",
      " 45% 45000/100000 [1:45:22<1:40:48,  9.09it/s]\n",
      "Iteration 45000: val_loss 3.1783, val_perplexity 24.0059, val_accuracy 0.3881\n",
      " 46% 45500/100000 [1:46:33<1:43:09,  8.81it/s]\n",
      "Iteration 45500: val_loss 3.1649, val_perplexity 23.6857, val_accuracy 0.3894\n",
      " 46% 46000/100000 [1:47:43<1:37:57,  9.19it/s]\n",
      "Iteration 46000: val_loss 3.1704, val_perplexity 23.8170, val_accuracy 0.3883\n",
      " 46% 46500/100000 [1:48:53<1:38:22,  9.06it/s]\n",
      "Iteration 46500: val_loss 3.1596, val_perplexity 23.5618, val_accuracy 0.3899\n",
      " 47% 47000/100000 [1:50:04<1:36:17,  9.17it/s]\n",
      "Iteration 47000: val_loss 3.1490, val_perplexity 23.3135, val_accuracy 0.3897\n",
      " 48% 47500/100000 [1:51:14<1:34:55,  9.22it/s]\n",
      "Iteration 47500: val_loss 3.1414, val_perplexity 23.1373, val_accuracy 0.3919\n",
      " 48% 48000/100000 [1:52:26<1:36:58,  8.94it/s]\n",
      "Iteration 48000: val_loss 3.1298, val_perplexity 22.8703, val_accuracy 0.3934\n",
      " 48% 48500/100000 [1:53:37<1:33:58,  9.13it/s]\n",
      "Iteration 48500: val_loss 3.1283, val_perplexity 22.8344, val_accuracy 0.3937\n",
      " 49% 49000/100000 [1:54:47<1:33:48,  9.06it/s]\n",
      "Iteration 49000: val_loss 3.1134, val_perplexity 22.4972, val_accuracy 0.3945\n",
      " 50% 49500/100000 [1:55:57<1:31:10,  9.23it/s]\n",
      "Iteration 49500: val_loss 3.1147, val_perplexity 22.5275, val_accuracy 0.3953\n",
      " 50% 50000/100000 [1:57:07<1:29:54,  9.27it/s]\n",
      "Iteration 50000: val_loss 3.1260, val_perplexity 22.7822, val_accuracy 0.3939\n",
      " 50% 50500/100000 [1:58:17<1:30:25,  9.12it/s]\n",
      "Iteration 50500: val_loss 3.1082, val_perplexity 22.3802, val_accuracy 0.3956\n",
      " 51% 51000/100000 [1:59:27<1:28:10,  9.26it/s]\n",
      "Iteration 51000: val_loss 3.0921, val_perplexity 22.0236, val_accuracy 0.3971\n",
      " 52% 51500/100000 [2:00:38<1:28:30,  9.13it/s]\n",
      "Iteration 51500: val_loss 3.0905, val_perplexity 21.9887, val_accuracy 0.3974\n",
      " 52% 52000/100000 [2:01:48<1:30:23,  8.85it/s]\n",
      "Iteration 52000: val_loss 3.0873, val_perplexity 21.9168, val_accuracy 0.3973\n",
      " 52% 52500/100000 [2:02:58<1:25:29,  9.26it/s]\n",
      "Iteration 52500: val_loss 3.0874, val_perplexity 21.9201, val_accuracy 0.3977\n",
      " 53% 53000/100000 [2:04:08<1:24:53,  9.23it/s]\n",
      "Iteration 53000: val_loss 3.0855, val_perplexity 21.8794, val_accuracy 0.3979\n",
      " 54% 53500/100000 [2:05:18<1:24:48,  9.14it/s]\n",
      "Iteration 53500: val_loss 3.0726, val_perplexity 21.5974, val_accuracy 0.4000\n",
      " 54% 54000/100000 [2:06:29<1:23:15,  9.21it/s]\n",
      "Iteration 54000: val_loss 3.0691, val_perplexity 21.5229, val_accuracy 0.3996\n",
      " 55% 54500/100000 [2:07:39<1:23:31,  9.08it/s]\n",
      "Iteration 54500: val_loss 3.0643, val_perplexity 21.4185, val_accuracy 0.3999\n",
      " 55% 55000/100000 [2:08:49<1:22:23,  9.10it/s]\n",
      "Iteration 55000: val_loss 3.0600, val_perplexity 21.3279, val_accuracy 0.4010\n",
      " 56% 55500/100000 [2:09:59<1:20:17,  9.24it/s]\n",
      "Iteration 55500: val_loss 3.0607, val_perplexity 21.3415, val_accuracy 0.4017\n",
      " 56% 56000/100000 [2:11:09<1:22:01,  8.94it/s]\n",
      "Iteration 56000: val_loss 3.0598, val_perplexity 21.3234, val_accuracy 0.4019\n",
      " 56% 56500/100000 [2:12:20<1:18:45,  9.21it/s]\n",
      "Iteration 56500: val_loss 3.0471, val_perplexity 21.0533, val_accuracy 0.4031\n",
      " 57% 57000/100000 [2:13:30<1:17:47,  9.21it/s]\n",
      "Iteration 57000: val_loss 3.0374, val_perplexity 20.8500, val_accuracy 0.4037\n",
      " 57% 57500/100000 [2:14:40<1:17:14,  9.17it/s]\n",
      "Iteration 57500: val_loss 3.0409, val_perplexity 20.9239, val_accuracy 0.4032\n",
      " 58% 58000/100000 [2:15:50<1:18:44,  8.89it/s]\n",
      "Iteration 58000: val_loss 3.0434, val_perplexity 20.9770, val_accuracy 0.4026\n",
      " 58% 58500/100000 [2:17:00<1:15:46,  9.13it/s]\n",
      "Iteration 58500: val_loss 3.0284, val_perplexity 20.6647, val_accuracy 0.4039\n",
      " 59% 59000/100000 [2:18:11<1:14:23,  9.18it/s]\n",
      "Iteration 59000: val_loss 3.0261, val_perplexity 20.6164, val_accuracy 0.4052\n",
      " 60% 59500/100000 [2:19:22<1:13:50,  9.14it/s]\n",
      "Iteration 59500: val_loss 3.0224, val_perplexity 20.5403, val_accuracy 0.4058\n",
      " 60% 60000/100000 [2:20:32<1:16:01,  8.77it/s]\n",
      "Iteration 60000: val_loss 3.0235, val_perplexity 20.5641, val_accuracy 0.4057\n",
      " 60% 60500/100000 [2:21:42<1:14:05,  8.89it/s]\n",
      "Iteration 60500: val_loss 3.0136, val_perplexity 20.3615, val_accuracy 0.4059\n",
      " 61% 61000/100000 [2:22:52<1:12:07,  9.01it/s]\n",
      "Iteration 61000: val_loss 3.0071, val_perplexity 20.2291, val_accuracy 0.4068\n",
      " 62% 61500/100000 [2:24:02<1:09:48,  9.19it/s]\n",
      "Iteration 61500: val_loss 3.0051, val_perplexity 20.1889, val_accuracy 0.4069\n",
      " 62% 62000/100000 [2:25:13<1:08:48,  9.20it/s]\n",
      "Iteration 62000: val_loss 2.9958, val_perplexity 20.0017, val_accuracy 0.4095\n",
      " 62% 62500/100000 [2:26:23<1:08:31,  9.12it/s]\n",
      "Iteration 62500: val_loss 3.0001, val_perplexity 20.0876, val_accuracy 0.4076\n",
      " 63% 63000/100000 [2:27:34<1:08:20,  9.02it/s]\n",
      "Iteration 63000: val_loss 2.9918, val_perplexity 19.9220, val_accuracy 0.4097\n",
      " 64% 63500/100000 [2:28:44<1:05:45,  9.25it/s]\n",
      "Iteration 63500: val_loss 2.9978, val_perplexity 20.0415, val_accuracy 0.4089\n",
      " 64% 64000/100000 [2:29:54<1:09:12,  8.67it/s]\n",
      "Iteration 64000: val_loss 2.9926, val_perplexity 19.9374, val_accuracy 0.4088\n",
      " 64% 64500/100000 [2:31:04<1:03:54,  9.26it/s]\n",
      "Iteration 64500: val_loss 2.9854, val_perplexity 19.7941, val_accuracy 0.4106\n",
      " 65% 65000/100000 [2:32:15<1:03:15,  9.22it/s]\n",
      "Iteration 65000: val_loss 2.9860, val_perplexity 19.8064, val_accuracy 0.4104\n",
      " 66% 65500/100000 [2:33:24<1:02:32,  9.19it/s]\n",
      "Iteration 65500: val_loss 2.9755, val_perplexity 19.5988, val_accuracy 0.4118\n",
      " 66% 66000/100000 [2:34:35<1:01:28,  9.22it/s]\n",
      "Iteration 66000: val_loss 2.9800, val_perplexity 19.6871, val_accuracy 0.4107\n",
      " 66% 66500/100000 [2:35:45<1:02:34,  8.92it/s]\n",
      "Iteration 66500: val_loss 2.9672, val_perplexity 19.4381, val_accuracy 0.4120\n",
      " 67% 67000/100000 [2:36:56<1:00:01,  9.16it/s]\n",
      "Iteration 67000: val_loss 2.9755, val_perplexity 19.5987, val_accuracy 0.4106\n",
      " 68% 67500/100000 [2:38:06<59:12,  9.15it/s]\n",
      "Iteration 67500: val_loss 2.9738, val_perplexity 19.5668, val_accuracy 0.4113\n",
      " 68% 68000/100000 [2:39:16<1:00:18,  8.84it/s]\n",
      "Iteration 68000: val_loss 2.9634, val_perplexity 19.3645, val_accuracy 0.4129\n",
      " 68% 68500/100000 [2:40:27<57:36,  9.11it/s]\n",
      "Iteration 68500: val_loss 2.9679, val_perplexity 19.4519, val_accuracy 0.4116\n",
      " 69% 69000/100000 [2:41:37<56:43,  9.11it/s]\n",
      "Iteration 69000: val_loss 2.9544, val_perplexity 19.1902, val_accuracy 0.4143\n",
      " 70% 69500/100000 [2:42:47<55:23,  9.18it/s]\n",
      "Iteration 69500: val_loss 2.9634, val_perplexity 19.3630, val_accuracy 0.4133\n",
      " 70% 70000/100000 [2:43:57<54:24,  9.19it/s]\n",
      "Iteration 70000: val_loss 2.9501, val_perplexity 19.1082, val_accuracy 0.4141\n",
      " 70% 70500/100000 [2:45:08<53:51,  9.13it/s]\n",
      "Iteration 70500: val_loss 2.9599, val_perplexity 19.2952, val_accuracy 0.4136\n",
      " 71% 71000/100000 [2:46:18<52:15,  9.25it/s]\n",
      "Iteration 71000: val_loss 2.9411, val_perplexity 18.9362, val_accuracy 0.4147\n",
      " 72% 71500/100000 [2:47:28<51:32,  9.22it/s]\n",
      "Iteration 71500: val_loss 2.9454, val_perplexity 19.0190, val_accuracy 0.4157\n",
      " 72% 72000/100000 [2:48:38<53:26,  8.73it/s]\n",
      "Iteration 72000: val_loss 2.9409, val_perplexity 18.9324, val_accuracy 0.4154\n",
      " 72% 72500/100000 [2:49:48<49:28,  9.26it/s]\n",
      "Iteration 72500: val_loss 2.9397, val_perplexity 18.9102, val_accuracy 0.4162\n",
      " 73% 73000/100000 [2:50:59<48:45,  9.23it/s]\n",
      "Iteration 73000: val_loss 2.9394, val_perplexity 18.9045, val_accuracy 0.4160\n",
      " 74% 73500/100000 [2:52:09<48:03,  9.19it/s]\n",
      "Iteration 73500: val_loss 2.9421, val_perplexity 18.9563, val_accuracy 0.4158\n",
      " 74% 74000/100000 [2:53:19<46:41,  9.28it/s]\n",
      "Iteration 74000: val_loss 2.9292, val_perplexity 18.7120, val_accuracy 0.4170\n",
      " 74% 74500/100000 [2:54:30<46:23,  9.16it/s]\n",
      "Iteration 74500: val_loss 2.9203, val_perplexity 18.5470, val_accuracy 0.4176\n",
      " 75% 75000/100000 [2:55:40<46:04,  9.04it/s]\n",
      "Iteration 75000: val_loss 2.9264, val_perplexity 18.6596, val_accuracy 0.4177\n",
      " 76% 75500/100000 [2:56:50<44:29,  9.18it/s]\n",
      "Iteration 75500: val_loss 2.9163, val_perplexity 18.4727, val_accuracy 0.4184\n",
      " 76% 76000/100000 [2:58:01<45:13,  8.84it/s]\n",
      "Iteration 76000: val_loss 2.9230, val_perplexity 18.5976, val_accuracy 0.4182\n",
      " 76% 76500/100000 [2:59:11<42:15,  9.27it/s]\n",
      "Iteration 76500: val_loss 2.9142, val_perplexity 18.4349, val_accuracy 0.4190\n",
      " 77% 77000/100000 [3:00:21<41:20,  9.27it/s]\n",
      "Iteration 77000: val_loss 2.9050, val_perplexity 18.2644, val_accuracy 0.4202\n",
      " 78% 77500/100000 [3:01:32<41:58,  8.93it/s]\n",
      "Iteration 77500: val_loss 2.9050, val_perplexity 18.2649, val_accuracy 0.4195\n",
      " 78% 78000/100000 [3:02:41<39:41,  9.24it/s]\n",
      "Iteration 78000: val_loss 2.9150, val_perplexity 18.4489, val_accuracy 0.4188\n",
      " 78% 78500/100000 [3:03:51<39:38,  9.04it/s]\n",
      "Iteration 78500: val_loss 2.8998, val_perplexity 18.1708, val_accuracy 0.4205\n",
      " 79% 79000/100000 [3:05:02<38:17,  9.14it/s]\n",
      "Iteration 79000: val_loss 2.9066, val_perplexity 18.2940, val_accuracy 0.4195\n",
      " 80% 79500/100000 [3:06:12<37:39,  9.07it/s]\n",
      "Iteration 79500: val_loss 2.9079, val_perplexity 18.3183, val_accuracy 0.4190\n",
      " 80% 80000/100000 [3:07:22<37:46,  8.83it/s]\n",
      "Iteration 80000: val_loss 2.8964, val_perplexity 18.1087, val_accuracy 0.4208\n",
      " 80% 80500/100000 [3:08:32<36:19,  8.95it/s]\n",
      "Iteration 80500: val_loss 2.9025, val_perplexity 18.2196, val_accuracy 0.4194\n",
      " 81% 81000/100000 [3:09:42<34:37,  9.15it/s]\n",
      "Iteration 81000: val_loss 2.8957, val_perplexity 18.0961, val_accuracy 0.4209\n",
      " 82% 81500/100000 [3:10:53<33:24,  9.23it/s]\n",
      "Iteration 81500: val_loss 2.9073, val_perplexity 18.3070, val_accuracy 0.4201\n",
      " 82% 82000/100000 [3:12:03<32:29,  9.23it/s]\n",
      "Iteration 82000: val_loss 2.8847, val_perplexity 17.8980, val_accuracy 0.4216\n",
      " 82% 82500/100000 [3:13:13<31:53,  9.14it/s]\n",
      "Iteration 82500: val_loss 2.9015, val_perplexity 18.2011, val_accuracy 0.4210\n",
      " 83% 83000/100000 [3:14:24<32:05,  8.83it/s]\n",
      "Iteration 83000: val_loss 2.8994, val_perplexity 18.1634, val_accuracy 0.4209\n",
      " 84% 83500/100000 [3:15:33<30:35,  8.99it/s]\n",
      "Iteration 83500: val_loss 2.8895, val_perplexity 17.9834, val_accuracy 0.4212\n",
      " 84% 84000/100000 [3:16:43<29:50,  8.94it/s]\n",
      "Iteration 84000: val_loss 2.8841, val_perplexity 17.8868, val_accuracy 0.4233\n",
      " 84% 84500/100000 [3:17:54<28:15,  9.14it/s]\n",
      "Iteration 84500: val_loss 2.8856, val_perplexity 17.9146, val_accuracy 0.4228\n",
      " 85% 85000/100000 [3:19:04<27:08,  9.21it/s]\n",
      "Iteration 85000: val_loss 2.8809, val_perplexity 17.8299, val_accuracy 0.4233\n",
      " 86% 85500/100000 [3:20:14<26:41,  9.05it/s]\n",
      "Iteration 85500: val_loss 2.8923, val_perplexity 18.0350, val_accuracy 0.4222\n",
      " 86% 86000/100000 [3:21:24<25:21,  9.20it/s]\n",
      "Iteration 86000: val_loss 2.8779, val_perplexity 17.7773, val_accuracy 0.4228\n",
      " 86% 86500/100000 [3:22:35<24:40,  9.12it/s]\n",
      "Iteration 86500: val_loss 2.8857, val_perplexity 17.9160, val_accuracy 0.4225\n",
      " 87% 87000/100000 [3:23:44<23:27,  9.24it/s]\n",
      "Iteration 87000: val_loss 2.8697, val_perplexity 17.6311, val_accuracy 0.4254\n",
      " 88% 87500/100000 [3:24:55<22:47,  9.14it/s]\n",
      "Iteration 87500: val_loss 2.8698, val_perplexity 17.6337, val_accuracy 0.4242\n",
      " 88% 88000/100000 [3:26:05<22:26,  8.91it/s]\n",
      "Iteration 88000: val_loss 2.8617, val_perplexity 17.4917, val_accuracy 0.4253\n",
      " 88% 88500/100000 [3:27:15<21:03,  9.10it/s]\n",
      "Iteration 88500: val_loss 2.8831, val_perplexity 17.8703, val_accuracy 0.4226\n",
      " 89% 89000/100000 [3:28:25<19:51,  9.24it/s]\n",
      "Iteration 89000: val_loss 2.8663, val_perplexity 17.5717, val_accuracy 0.4249\n",
      " 90% 89500/100000 [3:29:35<19:02,  9.19it/s]\n",
      "Iteration 89500: val_loss 2.8671, val_perplexity 17.5852, val_accuracy 0.4243\n",
      " 90% 90000/100000 [3:30:45<18:03,  9.23it/s]\n",
      "Iteration 90000: val_loss 2.8665, val_perplexity 17.5753, val_accuracy 0.4245\n",
      " 90% 90500/100000 [3:31:55<17:15,  9.17it/s]\n",
      "Iteration 90500: val_loss 2.8771, val_perplexity 17.7633, val_accuracy 0.4240\n",
      " 91% 91000/100000 [3:33:05<16:29,  9.09it/s]\n",
      "Iteration 91000: val_loss 2.8653, val_perplexity 17.5548, val_accuracy 0.4252\n",
      " 92% 91500/100000 [3:34:15<15:30,  9.13it/s]\n",
      "Iteration 91500: val_loss 2.8721, val_perplexity 17.6742, val_accuracy 0.4243\n",
      " 92% 92000/100000 [3:35:25<15:19,  8.70it/s]\n",
      "Iteration 92000: val_loss 2.8568, val_perplexity 17.4055, val_accuracy 0.4271\n",
      " 92% 92500/100000 [3:36:35<13:32,  9.23it/s]\n",
      "Iteration 92500: val_loss 2.8666, val_perplexity 17.5771, val_accuracy 0.4252\n",
      " 93% 93000/100000 [3:37:46<12:37,  9.24it/s]\n",
      "Iteration 93000: val_loss 2.8659, val_perplexity 17.5642, val_accuracy 0.4247\n",
      " 94% 93500/100000 [3:38:55<11:51,  9.14it/s]\n",
      "Iteration 93500: val_loss 2.8590, val_perplexity 17.4437, val_accuracy 0.4255\n",
      " 94% 94000/100000 [3:40:05<10:50,  9.22it/s]\n",
      "Iteration 94000: val_loss 2.8477, val_perplexity 17.2479, val_accuracy 0.4268\n",
      " 94% 94500/100000 [3:41:16<09:59,  9.17it/s]\n",
      "Iteration 94500: val_loss 2.8575, val_perplexity 17.4178, val_accuracy 0.4258\n",
      " 95% 95000/100000 [3:42:25<08:59,  9.26it/s]\n",
      "Iteration 95000: val_loss 2.8618, val_perplexity 17.4930, val_accuracy 0.4266\n",
      " 96% 95500/100000 [3:43:35<08:10,  9.17it/s]\n",
      "Iteration 95500: val_loss 2.8624, val_perplexity 17.5031, val_accuracy 0.4251\n",
      " 96% 96000/100000 [3:44:45<07:39,  8.71it/s]\n",
      "Iteration 96000: val_loss 2.8593, val_perplexity 17.4488, val_accuracy 0.4255\n",
      " 96% 96500/100000 [3:45:56<06:20,  9.21it/s]\n",
      "Iteration 96500: val_loss 2.8483, val_perplexity 17.2587, val_accuracy 0.4270\n",
      " 97% 97000/100000 [3:47:06<05:26,  9.19it/s]\n",
      "Iteration 97000: val_loss 2.8549, val_perplexity 17.3735, val_accuracy 0.4265\n",
      " 98% 97500/100000 [3:48:15<04:31,  9.20it/s]\n",
      "Iteration 97500: val_loss 2.8512, val_perplexity 17.3083, val_accuracy 0.4265\n",
      " 98% 98000/100000 [3:49:25<03:37,  9.21it/s]\n",
      "Iteration 98000: val_loss 2.8459, val_perplexity 17.2176, val_accuracy 0.4271\n",
      " 98% 98500/100000 [3:50:36<02:48,  8.88it/s]\n",
      "Iteration 98500: val_loss 2.8475, val_perplexity 17.2439, val_accuracy 0.4269\n",
      " 99% 99000/100000 [3:51:46<01:48,  9.25it/s]\n",
      "Iteration 99000: val_loss 2.8361, val_perplexity 17.0498, val_accuracy 0.4293\n",
      "100% 99500/100000 [3:52:56<00:54,  9.12it/s]\n",
      "Iteration 99500: val_loss 2.8479, val_perplexity 17.2519, val_accuracy 0.4277\n",
      "100% 100000/100000 [3:54:07<00:00,  7.12it/s]\n",
      "\n",
      "Training finished. Best model saved at: models/best_model_20251028_0739.pt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --max-iters 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Tt0Nhu2BYIL",
    "outputId": "b32965a0-4b32-403f-810f-3df54e9fb681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20251028_0739_loss_plot.png  LICENSE             README.md\n",
      "COMPARISONS.md               loss_plot.png       requirements.txt\n",
      "\u001b[0m\u001b[01;34mgemma_scratch\u001b[0m/               \u001b[01;34mmodels\u001b[0m/             \u001b[01;34mruns\u001b[0m/\n",
      "inference_custom.py          NOTICE              \u001b[01;34mtinystories_data\u001b[0m/\n",
      "inference_google_gemma.py    prepare_dataset.py  train_from_scratch.py\n",
      "install.sh                   pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhlWIG2Ifbrg",
    "outputId": "71a34b74-d5aa-4bec-96a3-0e2d4c861cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: models/ (stored 0%)\n",
      "  adding: models/best_model_20251028_0739.pt (deflated 32%)\n",
      "  adding: runs/ (stored 0%)\n",
      "  adding: runs/gemma_20251028_0739/ (stored 0%)\n",
      "  adding: runs/gemma_20251028_0739/events.out.tfevents.1761637162.86d48ca9593b.8023.0 (deflated 75%)\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "zip_filename = now.strftime(\"models_and_runs_%Y%m%d_%H%M%S.zip\")\n",
    "\n",
    "!zip -r {zip_filename} models runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "61j1JhRef0Gj"
   },
   "outputs": [],
   "source": [
    "!cp {zip_filename} \"/content/drive/My Drive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50df6764",
    "outputId": "9bfab3df-44a4-4eeb-fc80-aaf9c726244d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'models_and_runs_20251028_113340.zip' found in Google Drive.\n"
     ]
    }
   ],
   "source": [
    "drive_path = f\"/content/drive/My Drive/Colab Notebooks/{zip_filename}\"\n",
    "\n",
    "if os.path.exists(drive_path):\n",
    "    print(f\"File '{zip_filename}' found in Google Drive.\")\n",
    "else:\n",
    "    print(f\"File '{zip_filename}' not found in Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOz0u2anN7CzhzD1y6wBLLg",
   "gpuType": "A100",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}